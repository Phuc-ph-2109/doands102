{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doan_DS102.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcI_dfg2blzj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        " **#STEP 1:\n",
        "Read and statistic data**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSJ-yU_UbjOT",
        "colab_type": "text"
      },
      "source": [
        "*#Kết nối tới file data ở github*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crjdU1elcbig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!git clone 'https://github.com/Phuc-ph-2109/doands102.git'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-Jpq1NcbpgJ",
        "colab_type": "text"
      },
      "source": [
        "*#Đọc dữ liệu và thống kê*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntpa32mlbd9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "df = pd.read_csv(\"/content/doands102/vnexpress.csv\")\n",
        "#visualize số nhãn mỗi loại tập đầy đủ\n",
        "print(Counter(np.array(df['label'])))\n",
        "label = [\"positive\", \"negative\", \"neutral\"]\n",
        "count_label = [555, 530, 555]\n",
        "plt.bar(label, count_label, color = \"green\")\n",
        "plt.title(\"COUNT_LABEL_full\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Number\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukw3upqmc5h_",
        "colab_type": "text"
      },
      "source": [
        "*#Chia tập train test, và Visualize nhãn*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0jq60p4fvH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.iloc[:,0].values\n",
        "Y = df.iloc[:,1].values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size =0.8, random_state = 0, shuffle = True)\n",
        "\n",
        "#visualize số nhãn mỗi loại tập train\n",
        "print(Counter(np.array(Y_train)))\n",
        "count_label_train = [443, 429, 440]\n",
        "plt.bar(label, count_label_train, color = \"pink\")\n",
        "plt.title(\"Count Label Train\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Number\")\n",
        "plt.show()\n",
        "#visualize số nhãn mỗi loại tập test\n",
        "print(Counter(np.array(Y_test)))\n",
        "count_label_test = [112, 101, 115]\n",
        "plt.bar(label, count_label_test, color = \"blue\")\n",
        "plt.title(\"Count Label Test\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Number\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6iDy7RbdFz7",
        "colab_type": "text"
      },
      "source": [
        "**#STEP 2: Preprocessing data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHbzrSxgnN6",
        "colab_type": "text"
      },
      "source": [
        "*# Xóa kí tự đặc biệt, tách từ theo ngôn ngữ Việt*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiKcPOCHdNyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cài đặt thư viện pyvi\n",
        "!pip install pyvi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQMiNHK6g8Cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyvi import ViTokenizer, ViPosTagger\n",
        "import string\n",
        "import itertools\n",
        "def process_text(text):\n",
        "    \n",
        "    #1 Xóa kí tự đặc biệt, chuyển về chữ thường\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    nopunc = nopunc.lower()\n",
        "    #2 Gộp các kí tự trùng lặp\n",
        "    nopunc = ''.join(ch for ch, _ in itertools.groupby(nopunc))\n",
        "    #3 Vitokennizer (Tách từ theo từ điển việt nam (độ chính xác 80%))\n",
        "    review = ViTokenizer.tokenize(nopunc)\n",
        "    return review"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uGi5Z-ShkAv",
        "colab_type": "text"
      },
      "source": [
        "*#Tạo bags of Word, sử dụng TfidfTransformer để giảm những từ xuất hiện nhiều nhưng vô nghĩa*\n",
        "*Sử dụng pipeline kết hợp*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i059gY-ehjGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Model 1 xử dụng MultinomialNB của Naive Bayes\n",
        "model1 = Pipeline([('vect', CountVectorizer(analyzer=process_text)),('tfidf', TfidfTransformer()),('clf1', MultinomialNB()),])\n",
        "\n",
        "# Model 2 xử dụng Suport Vector Machine\n",
        "model2 = Pipeline([('vect', CountVectorizer(analyzer=process_text)),('tfidf', TfidfTransformer()),('clf2', SVC()),])\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJGo4NtodOft",
        "colab_type": "text"
      },
      "source": [
        "**#STEP 3: Training model & Save model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHyKnm2UdW14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# Model 1\n",
        "model1.fit(X_train,Y_train)\n",
        "filename = 'NaiveBayes_model.sav'\n",
        "pickle.dump(model1, open(filename, 'wb'))\n",
        "# Model 2\n",
        "model2.fit(X_train,Y_train)\n",
        "filename = 'SVM_model.sav'\n",
        "pickle.dump(model2, open(filename, 'wb'))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuNLA_xMdXbe",
        "colab_type": "text"
      },
      "source": [
        "**#STEP 4: Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKNoBbbUdc5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "#Test set model 1\n",
        "cm = confusion_matrix(Y_test, model1.predict(X_test))\n",
        "plt.title('Confusion matrix on Test set Model 1:')\n",
        "sns.heatmap(cm, annot = True, fmt = 'g', cmap = 'OrRd', annot_kws = {\"size\": 10})\n",
        "plt.savefig('confusionmatrix_test_Logistic.png')\n",
        "plt.show()\n",
        "\n",
        "#Test set model 2\n",
        "cm = confusion_matrix(Y_test, model2.predict(X_test))\n",
        "plt.title('Confusion matrix on Test set Model 2:')\n",
        "sns.heatmap(cm, annot = True, fmt = 'g', cmap = 'OrRd', annot_kws = {\"size\": 10})\n",
        "plt.savefig('confusionmatrix_test_SVM.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SVwV2HtddLx",
        "colab_type": "text"
      },
      "source": [
        "**#STEP 5: Review the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53-zk4YdqGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "#Model 1\n",
        "print(classification_report(Y_test, model1.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOdMMXk_lwKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model 2\n",
        "print(classification_report(Y_test, model2.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mG3Avsul1pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compare model 1\n",
        "df_compare = pd.DataFrame()\n",
        "df_compare['cmt'] = X_test\n",
        "df_compare['label'] = Y_test\n",
        "df_compare['Predict label'] = model1.predict(X_test)\n",
        "print('Compare on 20 line in test set:')\n",
        "print(df_compare.head(20))\n",
        "\n",
        "df_compare.to_excel('predict_NaiveBayes.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8oMTVgtl6OJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compare model 2\n",
        "df_compare = pd.DataFrame()\n",
        "df_compare['cmt'] = X_test\n",
        "df_compare['label'] = Y_test\n",
        "df_compare['Predict label'] = model2.predict(X_test)\n",
        "print('Compare on 20 line in test set:')\n",
        "print(df_compare.head(20))\n",
        "\n",
        "df_compare.to_excel('predict_SVM.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}